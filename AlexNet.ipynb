{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19b9a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bad240b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder (or file) names:\n",
      "['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root_dir = \"C:\\\\Users\\\\saiki\\\\OneDrive\\\\Desktop\\\\BTech\\\\data sets\\\\Rice_Image_Dataset\\\\Rice_Image_Dataset\"\n",
    "f_names = [f_name for f_name in os.listdir(root_dir)]\n",
    "print(f\"Folder (or file) names:\\n{f_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7a4b617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rice classes:\n",
      "Arborio, Basmati, Ipsala, Jasmine, Karacadag\n"
     ]
    }
   ],
   "source": [
    "rice_classes = f_names.copy()\n",
    "print(f\"Rice classes:\\n{', '.join(rice_classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44a31b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_counts = {rice_class: len(os.listdir(os.path.join(root_dir, rice_class))) for rice_class in rice_classes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9ebfde6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rice_list = []\n",
    "for rice_class in rice_classes:\n",
    "    class_dir = os.path.join(root_dir, rice_class)\n",
    "    for img_path in os.listdir(class_dir):\n",
    "        full_path = os.path.join(class_dir, img_path)\n",
    "        rice_list.append((full_path, rice_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64ef353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(rice_list, columns=[\"File_Path\", \"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27994d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4bfb28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples is 75000\n"
     ]
    }
   ],
   "source": [
    "total_samples = df.shape[0]\n",
    "print(f\"Total number of samples is {total_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3aa5cddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11250.0, 52500.0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.15 * total_samples, 0.7 * total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "faaf7cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = df[:52500].copy() # 70% of data\n",
    "validate_set = df[52500:63750].copy()  # 15% of data\n",
    "test_set = df[63750:].copy() # 15% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "955e0162",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8ba9ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52500 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = data_generator.flow_from_dataframe(\n",
    "  dataframe=train_set,\n",
    "  x_col=\"File_Path\",\n",
    "  y_col=\"Label\",\n",
    "  target_size=(img_height, img_width),\n",
    "  batch_size=batch_size,\n",
    "  class_mode=\"categorical\",\n",
    "  shuffle=True,\n",
    "  seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "235edbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11250 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = data_generator.flow_from_dataframe(\n",
    "  dataframe=validate_set,\n",
    "  x_col=\"File_Path\",\n",
    "  y_col=\"Label\",\n",
    "  target_size=(img_height, img_width),\n",
    "  batch_size=batch_size,\n",
    "  class_mode=\"categorical\",\n",
    "  shuffle=False,\n",
    "  seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a7fd675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11250 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = data_generator.flow_from_dataframe(\n",
    "  dataframe=test_set,\n",
    "  x_col=\"File_Path\",\n",
    "  y_col=\"Label\",\n",
    "  target_size=(img_height, img_width),\n",
    "  batch_size=batch_size,\n",
    "  class_mode=\"categorical\",\n",
    "  shuffle=False,\n",
    "  seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d528c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (128, 224, 224, 3) (Batches = 411)\n",
      "Train label: (128, 5)\n",
      "\n",
      "Validation Shape: (128, 224, 224, 3) (Batches = 88)\n",
      "Validation label: (128, 5)\n",
      "\n",
      "Test Shape: (128, 224, 224, 3) (Batches = 88)\n",
      "Test label: (128, 5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_generator:\n",
    "    print(f\"Train Shape: {image_batch.shape} (Batches = {len(train_generator)})\")\n",
    "    print(f\"Train label: {labels_batch.shape}\\n\")\n",
    "    break\n",
    "    \n",
    "for image_batch, labels_batch in validation_generator:\n",
    "    print(f\"Validation Shape: {image_batch.shape} (Batches = {len(validation_generator)})\")\n",
    "    print(f\"Validation label: {labels_batch.shape}\\n\")\n",
    "    break\n",
    "    \n",
    "for image_batch, labels_batch in test_generator:\n",
    "    print(f\"Test Shape: {image_batch.shape} (Batches = {len(test_generator)})\")\n",
    "    print(f\"Test label: {labels_batch.shape}\\n\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ccef7c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiki\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "AlexNet_model = models.Sequential([\n",
    "    layers.Conv2D(96, 11, strides=4, activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "    layers.Conv2D(256, 5, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "    layers.Conv2D(384, 3, activation='relu'),\n",
    "    layers.Conv2D(384, 3, activation='relu'),\n",
    "    layers.Conv2D(256, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=3, strides=2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e2c0f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">34,944</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">614,656</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">885,120</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,327,488</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">884,992</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,052,672</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,485</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │          \u001b[38;5;34m34,944\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │             \u001b[38;5;34m384\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m96\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m614,656\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m384\u001b[0m)           │         \u001b[38;5;34m885,120\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m384\u001b[0m)           │       \u001b[38;5;34m1,327,488\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m884,992\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │       \u001b[38;5;34m1,052,672\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │      \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │          \u001b[38;5;34m20,485\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,603,077</span> (82.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,603,077\u001b[0m (82.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,602,373</span> (82.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,602,373\u001b[0m (82.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AlexNet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d99489a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet_model.compile(loss=BinaryCrossentropy(),\n",
    "                  optimizer=Adam(learning_rate=0.001),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51b230cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiki\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2392s\u001b[0m 6s/step - accuracy: 0.8027 - loss: 0.2806 - val_accuracy: 0.6644 - val_loss: 0.2766\n",
      "Epoch 2/10\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1191s\u001b[0m 3s/step - accuracy: 0.9636 - loss: 0.0449 - val_accuracy: 0.6666 - val_loss: 0.7491\n",
      "Epoch 3/10\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1045s\u001b[0m 3s/step - accuracy: 0.9770 - loss: 0.0293 - val_accuracy: 0.5585 - val_loss: 0.5306\n",
      "Epoch 4/10\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1045s\u001b[0m 3s/step - accuracy: 0.9823 - loss: 0.0237 - val_accuracy: 0.7820 - val_loss: 0.2519\n",
      "Epoch 5/10\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2256s\u001b[0m 5s/step - accuracy: 0.9810 - loss: 0.0243 - val_accuracy: 0.9438 - val_loss: 0.0546\n",
      "Epoch 6/10\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2166s\u001b[0m 5s/step - accuracy: 0.9863 - loss: 0.0200 - val_accuracy: 0.9183 - val_loss: 0.0987\n",
      "Epoch 7/10\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3202s\u001b[0m 8s/step - accuracy: 0.9881 - loss: 0.0167 - val_accuracy: 0.6334 - val_loss: 0.8222\n",
      "Epoch 8/10\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2013s\u001b[0m 5s/step - accuracy: 0.9870 - loss: 0.0166 - val_accuracy: 0.6708 - val_loss: 0.8844\n",
      "Epoch 9/10\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1048s\u001b[0m 3s/step - accuracy: 0.9895 - loss: 0.0139 - val_accuracy: 0.9246 - val_loss: 0.0972\n",
      "Epoch 10/10\n",
      "\u001b[1m411/411\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1047s\u001b[0m 3s/step - accuracy: 0.9908 - loss: 0.0127 - val_accuracy: 0.9244 - val_loss: 0.1043\n"
     ]
    }
   ],
   "source": [
    "AlexNet = AlexNet_model.fit(train_generator,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "555cf34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet_model.save('AlexNet_model.keras')\n",
    "history_alex = AlexNet.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "509a211f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiki\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 22 variables whereas the saved optimizer has 42 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "load_Alex = tf.keras.models.load_model('AlexNet_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0bcdfac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_matrix, class_labels, model_name):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greens', xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title(f'Confusion Matrix of {model_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "64b00337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_report(true_classes, predicted_classes, class_labels, model_name):\n",
    "    print(f\"Classification Report for {model_name} Model:\\n\")\n",
    "    print(classification_report(true_classes, predicted_classes, target_names=class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca5d4d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(load_model, test_generator, class_labels, model_name):\n",
    "    predictions = load_model.predict(test_generator)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    conf_matrix = confusion_matrix(true_classes, predicted_classes)   \n",
    "    return conf_matrix, true_classes, predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c1414091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiki\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 954ms/step\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_AlexNet, true_classes_AlexNet, predicted_classes_AlexNet = evaluate_model(load_Alex, test_generator, rice_classes, \"AlexNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "174e8e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "495"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions != labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9035e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(predictions == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e9227cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(conf_matrix, class_labels, model_name):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greens', xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title(f'Confusion Matrix of {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "def print_classification_report(true_classes, predicted_classes, class_labels, model_name):\n",
    "    print(f\"Classification Report for {model_name} Model:\\n\")\n",
    "    print(classification_report(true_classes, predicted_classes, target_names=class_labels))\n",
    "\n",
    "def evaluate_model(load_model, test_generator, class_labels, model_name):\n",
    "    predictions = load_model.predict(test_generator)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    return conf_matrix, true_classes, predicted_classes\n",
    "conf_matrix_AlexNet, true_classes_AlexNet, predicted_classes_AlexNet = evaluate_model(load_Alex, test_generator, rice_classes, \"AlexNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7deba8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model expects input shape: (None, 224, 224, 3)\n",
      "Image shape before prediction: (1, 224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569ms/step\n",
      "Predictions: [[4.3225264e-06 9.8220336e-01 1.0033370e-05 1.7780585e-02 1.6814392e-06]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "model_path = \"AlexNet_model.keras\" \n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "img_path = \"C:\\\\Users\\\\saiki\\\\OneDrive\\\\Desktop\\\\BTech\\\\data sets\\\\Rice_Image_Dataset\\\\Rice_Image_Dataset\\\\Basmati\\\\Basmati (1).jpg\"\n",
    "\n",
    "print(\"Model expects input shape:\", model.input_shape) \n",
    "\n",
    "expected_size = (227, 227) if model.input_shape[1] == 227 else (224, 224)\n",
    "img = image.load_img(img_path, target_size=expected_size)  \n",
    "\n",
    "img_array = image.img_to_array(img)  \n",
    "img_array = np.expand_dims(img_array, axis=0)  \n",
    "img_array = img_array.astype(\"float32\") / 255.0  \n",
    "\n",
    "print(\"Image shape before prediction:\", img_array.shape)  \n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eeb519b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model expects input size: (224, 224)\n",
      "Image shape before prediction: (1, 224, 224, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step\n",
      "Predictions: [[4.3225264e-06 9.8220336e-01 1.0033370e-05 1.7780585e-02 1.6814392e-06]]\n",
      "Predicted Rice Class: arborio (Index: 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "rice_classes = ['basmati', 'arborio', 'ispala', 'karacadag', 'jasmine']\n",
    "\n",
    "model_path = \"AlexNet_model.keras\"  \n",
    "model = tf.keras.models.load_model(model_path)\n",
    "img_path = \"C:\\\\Users\\\\saiki\\\\OneDrive\\\\Desktop\\\\BTech\\\\data sets\\\\Rice_Image_Dataset\\\\Rice_Image_Dataset\\\\Basmati\\\\Basmati (1).jpg\"\n",
    "input_size = model.input_shape[1:3] \n",
    "print(\"Model expects input size:\", input_size)\n",
    "img = image.load_img(img_path, target_size=input_size)\n",
    "img_array = image.img_to_array(img) \n",
    "img_array = np.expand_dims(img_array, axis=0) \n",
    "img_array = img_array.astype(\"float32\") / 255.0  \n",
    "\n",
    "print(\"Image shape before prediction:\", img_array.shape)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "predicted_class_index = np.argmax(predictions)  \n",
    "predicted_class = rice_classes[predicted_class_index]  \n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "print(f\"Predicted Rice Class: {predicted_class} (Index: {predicted_class_index})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
